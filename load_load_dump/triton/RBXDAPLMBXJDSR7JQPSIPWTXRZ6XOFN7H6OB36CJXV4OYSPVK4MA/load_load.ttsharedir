#loc = loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0)
#loc1 = loc(unknown)
#loc6 = loc("/home/devro/workspace/ts_sandbox/load_load.py":18:16)
#map = affine_map<(d0) -> (d0)>
#loc10 = loc("a_ptr"(#loc))
#loc11 = loc("y"(#loc))
#loc12 = loc("b_ptr"(#loc))
#loc13 = loc("size0"(#loc))
#loc14 = loc("stride0"(#loc))
#loc15 = loc("num0"(#loc))
#loc19 = loc("x"(#loc6))
module {
  func.func @load_load(%arg0: memref<*xf32> {tt.divisibility = 16 : i32} loc("a_ptr"(#loc)), %arg1: memref<*xi32> {tt.divisibility = 16 : i32} loc("y"(#loc)), %arg2: memref<*xf32> {tt.divisibility = 16 : i32} loc("b_ptr"(#loc)), %arg3: i32 {tt.divisibility = 16 : i32} loc("size0"(#loc)), %arg4: i32 {tt.divisibility = 16 : i32} loc("stride0"(#loc)), %arg5: i32 loc("num0"(#loc)), %arg6: i32 loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0), %arg7: i32 loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0), %arg8: i32 loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0), %arg9: i32 loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0), %arg10: i32 loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0), %arg11: i32 loc("/home/devro/workspace/ts_sandbox/load_load.py":10:0)) {
    %c1 = arith.constant 1 : index loc(#loc1)
    %c0 = arith.constant 0 : index loc(#loc1)
    %cst = arith.constant 2.000000e+00 : f32 loc(#loc1)
    %c1024 = arith.constant 1024 : index loc(#loc1)
    %cst_0 = arith.constant 0.000000e+00 : f32 loc(#loc1)
    %c1024_i32 = arith.constant 1024 : i32 loc(#loc1)
    %0 = tensor.empty() : tensor<1024xf32> loc(#loc1)
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1024xf32>) -> tensor<1024xf32> loc(#loc1)
    %2 = arith.muli %arg9, %c1024_i32 : i32 loc(#loc16)
    %3 = arith.index_cast %2 : i32 to index loc(#loc3)
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [%3], sizes: [1024], strides: [1] : memref<*xi32> to memref<1024xi32, strided<[1], offset: ?>> loc(#loc17)
    %4 = arith.addi %3, %c1024 : index loc(#loc18)
    %5 = arith.index_cast %arg3 : i32 to index loc(#loc18)
    %6 = arith.minsi %4, %5 : index loc(#loc18)
    %7 = arith.maxsi %6, %3 : index loc(#loc18)
    %8 = arith.subi %7, %3 : index loc(#loc18)
    %alloc = memref.alloc() : memref<1024xi32> loc(#loc18)
    %subview = memref.subview %reinterpret_cast[0] [%8] [1] : memref<1024xi32, strided<[1], offset: ?>> to memref<?xi32, strided<[1], offset: ?>> loc(#loc18)
    %subview_1 = memref.subview %alloc[0] [%8] [1] : memref<1024xi32> to memref<?xi32, strided<[1]>> loc(#loc18)
    memref.copy %subview, %subview_1 : memref<?xi32, strided<[1], offset: ?>> to memref<?xi32, strided<[1]>> loc(#loc18)
    %9 = bufferization.to_tensor %alloc restrict writable : memref<1024xi32> to tensor<1024xi32> loc(#loc18)
    %alloc_2 = memref.alloc() : memref<1024xf32> loc(#loc19)
    %10 = arith.cmpi slt, %8, %c1024 : index loc(#loc19)
    scf.if %10 {
      linalg.fill ins(%cst_0 : f32) outs(%alloc_2 : memref<1024xf32>) loc(#loc19)
    } loc(#loc19)
    %11 = arith.minsi %8, %c1024 : index loc(#loc19)
    scf.for %arg12 = %c0 to %11 step %c1 {
      %extracted = tensor.extract %9[%arg12] : tensor<1024xi32> loc(#loc19)
      %14 = arith.index_cast %extracted : i32 to index loc(#loc19)
      %reinterpret_cast_5 = memref.reinterpret_cast %arg0 to offset: [%14], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> loc(#loc20)
      %subview_6 = memref.subview %alloc_2[%arg12] [1] [1] : memref<1024xf32> to memref<1xf32, strided<[1], offset: ?>> loc(#loc19)
      memref.copy %reinterpret_cast_5, %subview_6 : memref<1xf32, strided<[1], offset: ?>> to memref<1xf32, strided<[1], offset: ?>> loc(#loc19)
    } loc(#loc19)
    %12 = bufferization.to_tensor %alloc_2 restrict writable : memref<1024xf32> to tensor<1024xf32> loc(#loc19)
    %13 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%12, %1 : tensor<1024xf32>, tensor<1024xf32>) outs(%12 : tensor<1024xf32>) {
    ^bb0(%in: f32 loc("x"(#loc6)), %in_5: f32 loc(unknown), %out: f32 loc("x"(#loc6))):
      %14 = arith.mulf %in, %in_5 : f32 loc(#loc21)
      linalg.yield %14 : f32 loc(#loc21)
    } -> tensor<1024xf32> loc(#loc21)
    %reinterpret_cast_3 = memref.reinterpret_cast %arg2 to offset: [%3], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>> loc(#loc3)
    %extracted_slice = tensor.extract_slice %13[0] [%8] [1] : tensor<1024xf32> to tensor<?xf32> loc(#loc9)
    %subview_4 = memref.subview %reinterpret_cast_3[0] [%8] [1] : memref<1024xf32, strided<[1], offset: ?>> to memref<?xf32, strided<[1], offset: ?>> loc(#loc9)
    bufferization.materialize_in_destination %extracted_slice in writable %subview_4 : (tensor<?xf32>, memref<?xf32, strided<[1], offset: ?>>) -> () loc(#loc9)
    return loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("/home/devro/workspace/ts_sandbox/load_load.py":12:20)
#loc3 = loc("/home/devro/workspace/ts_sandbox/load_load.py":21:21)
#loc4 = loc("/home/devro/workspace/ts_sandbox/load_load.py":16:22)
#loc5 = loc("/home/devro/workspace/ts_sandbox/load_load.py":16:18)
#loc7 = loc("/home/devro/workspace/ts_sandbox/load_load.py":18:24)
#loc8 = loc("/home/devro/workspace/ts_sandbox/load_load.py":20:15)
#loc9 = loc("/home/devro/workspace/ts_sandbox/load_load.py":21:30)
#loc16 = loc("offsets"(#loc2))
#loc17 = loc("idx"(#loc4))
#loc18 = loc("idx"(#loc5))
#loc20 = loc("x"(#loc7))
#loc21 = loc("result"(#loc8))

